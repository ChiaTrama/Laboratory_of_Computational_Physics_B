{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21910696-5f5e-4fcf-8671-b94c4eb0b7f7",
   "metadata": {},
   "source": [
    "## Dataset creation for simulation based bayesian inference\n",
    "This series of notebooks are constructed with ease of use in mind one can stop at every major step without fear of losing too much computational time. \\\n",
    "The intended order of use is as follows: \n",
    "### dataset_creation -> inference -> posterior_analysis.\n",
    "pickle_dataset_merge.py can be used to merge multiple datasets of the same type, parsings_functions contains all the functions used to manage the rudimental database. \\\n",
    "simulations_model1.py contains the actual code of the model, in this case the quartic potential model that cannot be analitically computed. \\\n",
    "Running time for an i7 8700k is approximately 0.020 s/it, so for 10000 simulations it takes roughly 2.5 minutes, one can experiment with different parameters if wanted.\n",
    "\n",
    "For displaying and saving we used 1000 simulations, feel free to change that if needed.\n",
    "\n",
    "#### important: \n",
    "to run the simulations you need a few more packages other than the ones imported below. \\\n",
    "you can do so with this command directly from this notebook if your enviroment permissions' allow it: !pip install numba icc_rt rocket-fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9c4f90e-a7a4-4028-b355-f9a08b584ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from sbi import utils as utils\n",
    "from sbi.inference import SNPE, simulate_for_sbi\n",
    "from sbi.utils.user_input_checks import (\n",
    "    check_sbi_inputs,\n",
    "    process_prior,\n",
    "    process_simulator,\n",
    ")\n",
    "\n",
    "from parsing_functions import save_pickle_data\n",
    "from simulations_model1 import simulator_sbi\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc198c04-6b65-4e09-bddf-6444ccfc4e28",
   "metadata": {},
   "source": [
    "# Dataset creation with simulate_for_sbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e0f7511-debe-4ea0-ab3a-72979be82a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_tensor = torch.tensor([0,0.1,0])\n",
    "high_tensor = torch.tensor([4,3,15])\n",
    "\n",
    "dt = 1e-2\n",
    "oversampling = 5\n",
    "prerun = 1e3\n",
    "Npts = 5e4\n",
    "\n",
    "\n",
    "def simulator_to_sbi(pars):\n",
    "    return simulator_sbi(np.array(pars), dt, oversampling, int(prerun),int(Npts))\n",
    "\n",
    "\n",
    "prior_sbi = utils.BoxUniform(low=low_tensor, high=high_tensor)\n",
    "\n",
    "# Check prior, return PyTorch prior.\n",
    "prior, num_parameters, prior_returns_numpy = process_prior(prior_sbi)\n",
    "\n",
    "# Check simulator, returns PyTorch simulator able to simulate batches.\n",
    "simulator = process_simulator(simulator_to_sbi, prior, prior_returns_numpy)\n",
    "\n",
    "# Consistency check after making ready for sbi.\n",
    "check_sbi_inputs(simulator, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ace5441-6b8e-404b-b592-6be83de0cb39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d2a76a137f47a48fdd639962142707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 1000 simulations in 100 batches.:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean time per iteration:  0.0315707368850708\n"
     ]
    }
   ],
   "source": [
    "num_simulations=1000\n",
    "num_workers=10\n",
    "sim_batch_size=int(num_simulations/(num_workers*10))\n",
    "\n",
    "#to use parallel processing you need python<3.11\n",
    "start=time.time()\n",
    "theta, x = simulate_for_sbi(simulator, proposal=prior, num_simulations=num_simulations, \n",
    "                            num_workers=num_workers, simulation_batch_size=sim_batch_size)\n",
    "end=time.time()\n",
    "\n",
    "#bsize = 10, nworkers=10, ~ 0.62s/it\n",
    "#new sim with 100 batches ~0.29s/it, same with 10 batches\n",
    "\n",
    "print('mean time per iteration: ', (end-start)/num_simulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2519f72b-1e9a-4397-acd8-0eaa5922e4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset at saved_datasets/dataset_1000sim_5e+04np_1e-02dt_5os_1e+03pre.pickle\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'saved_datasets/dataset_1000sim_5e+04np_1e-02dt_5os_1e+03pre.pickle'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving dataset for future use\n",
    "save_dir = 'saved_datasets'\n",
    "data = {\n",
    "    'theta': theta,\n",
    "    'x': x,\n",
    "    'num_simulations': num_simulations,\n",
    "    'Npts': Npts,\n",
    "    'dt': dt,\n",
    "    'oversampling': oversampling,\n",
    "    'prerun': prerun,\n",
    "    'low_tensor': low_tensor,\n",
    "    'high_tensor': high_tensor,\n",
    "    'data_type': 'full'  # Indicates the type of the data\n",
    "    \n",
    "}\n",
    "\n",
    "save_pickle_data(data=data, folder_path=save_dir, prefix = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d021637-5755-46c2-9945-5b67922affa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
